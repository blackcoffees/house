2019-01-25 10:29:56,648 - CommonUtils.py[line:311] - ERROR: 删除日志成功
2019-01-25 10:30:21,335 - log.py[line:146] - INFO: Scrapy %(version)s started (bot: %(bot)s)
2019-01-25 10:30:21,341 - log.py[line:149] - INFO: Versions: %(versions)s
2019-01-25 10:30:21,354 - crawler.py[line:38] - INFO: Overridden settings: %(settings)r
2019-01-25 10:30:21,408 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:30:21,855 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:30:21,861 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:30:21,867 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:30:21,881 - engine.py[line:256] - INFO: Spider opened
2019-01-25 10:30:21,891 - logstats.py[line:48] - INFO: Crawled %(pages)d pages (at %(pagerate)d pages/min), scraped %(items)d items (at %(itemrate)d items/min)
2019-01-25 10:30:21,892 - middlewares.py[line:109] - INFO: Spider opened: building
2019-01-25 10:30:22,529 - scraper.py[line:208] - ERROR: Error downloading %(request)s
Traceback (most recent call last):
  File "E:\virtualenv\python27\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-01-25 10:30:22,630 - engine.py[line:295] - INFO: Closing spider (%(reason)s)
2019-01-25 10:30:22,631 - statscollectors.py[line:47] - INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'downloader/request_bytes': 1088,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 1293,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 1, 25, 2, 30, 22, 631000),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2019, 1, 25, 2, 30, 21, 893000)}
2019-01-25 10:30:22,632 - engine.py[line:326] - INFO: Spider closed (%(reason)s)
2019-01-25 10:30:57,105 - log.py[line:146] - INFO: Scrapy %(version)s started (bot: %(bot)s)
2019-01-25 10:30:57,111 - log.py[line:149] - INFO: Versions: %(versions)s
2019-01-25 10:30:57,122 - crawler.py[line:38] - INFO: Overridden settings: %(settings)r
2019-01-25 10:30:57,177 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:30:57,595 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:30:57,601 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:30:57,605 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:31:04,881 - ProxyIPUtil.py[line:163] - INFO: 测试代理IP,切换代理IP:222.16.83.18:80
2019-01-25 10:31:04,961 - _legacy.py[line:154] - CRITICAL: Unhandled error in Deferred:
2019-01-25 10:31:04,961 - _legacy.py[line:154] - CRITICAL: 
Traceback (most recent call last):
  File "E:\virtualenv\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "E:\virtualenv\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "E:\virtualenv\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "E:\workspace\pycharm\house_spider\scrapy_spider\spiders\house.py", line 103, in start_requests
    return [Request(url, meta={"proxy": "http://" + self.proxy_ip})]
TypeError: cannot concatenate 'str' and 'bool' objects
2019-01-25 10:31:40,128 - log.py[line:146] - INFO: Scrapy %(version)s started (bot: %(bot)s)
2019-01-25 10:31:40,134 - log.py[line:149] - INFO: Versions: %(versions)s
2019-01-25 10:31:40,147 - crawler.py[line:38] - INFO: Overridden settings: %(settings)r
2019-01-25 10:31:40,196 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:31:40,618 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:31:40,622 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:31:40,628 - middleware.py[line:53] - INFO: Enabled %(componentname)ss:
%(enabledlist)s
2019-01-25 10:34:04,151 - ProxyIPUtil.py[line:163] - INFO: 测试代理IP,切换代理IP:119.57.108.65:53281
2019-01-25 10:35:18,729 - RealEstate.py[line:51] - INFO: 渝北：65
